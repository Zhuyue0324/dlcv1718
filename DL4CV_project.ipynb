{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection in the street"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is the main notebook (temporary just a structure now of all steps that we can do) for our DL4CV project. Our aim is to detect the object in the street by means of a convolutional neural network. The detection will be like a segmentation task with find out what each pixel of the object in a photo belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.3 |Anaconda, Inc.| (default, Oct 13 2017, 12:02:49) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.utils.data.sampler as Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This step should be to load the data images and the label images (by pixel), while doing feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--In leftImg8bit.zip, the train and test images are all 8-bit 2048*1024 pixels png type images. \n",
    "\n",
    "--In gtCoarse, the train and test labels are all 2048*1024 pixels png type images, which ONLY color the road in pink and the small objects on it in blue, the other pixels are black.\n",
    "\n",
    "-- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelscsv = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictlabel = {}\n",
    "for i in range(labelscsv.shape[0]):\n",
    "    val=np.ones(labelscsv.shape[1]-1)\n",
    "    for j in range(labelscsv.shape[1]-1):\n",
    "        val[j]=labelscsv.iloc[i][j+1]\n",
    "    val1=torch.from_numpy(val)\n",
    "    dictlabel[labelscsv.iloc[i][0]] = val1\n",
    "dictlabel.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labeltransformtrain(input):\n",
    "    return(torch.Tensor.float(dictlabel[datatrain.classes[input]]))\n",
    "\n",
    "def labeltransformvalidation(input):\n",
    "    return(torch.Tensor.float(dictlabel[datavalidation.classes[input]]))\n",
    "\n",
    "def labeltransformtest(input):\n",
    "    return(torch.Tensor.float(dictlabel[datatest.classes[input]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pre-training of the images contains the following steps:\n",
    "\n",
    "--Using transform.Scale to rize the images into width = 256 (To be modified)\n",
    "\n",
    "--take the center part with 224 x 224 (We know that the resnet requires an input of 224 x 224)\n",
    "\n",
    "--transforms each pixel from [0,255] to [0,1] \n",
    "--> Are we sure we want to do this? Won't we lose resolution? \n",
    "\n",
    "--Normalisation for resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Scale(256),\n",
    "     transforms.CenterCrop(224),     \n",
    "     transforms.ToTensor(),\n",
    "#     transforms.Lambda(lambda x: Normal(x))])\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "datatrain = ImageFolder(root='/local/zhu/Stage Yue code/exp2/train90', transform=transform, target_transform=labeltransformtrain)\n",
    "# paths need to be changed ... best to use environment variables (ie. DL4CV_ROOT)\n",
    "datavalidation = ImageFolder(root='/local/zhu/Stage Yue code/exp2/validation10', transform=transform, target_transform=labeltransformvalidation)\n",
    "datatest = ImageFolder(root='/local/zhu/Stage Yue code/exp2/test', transform=transform, target_transform=labeltransformtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of the data after feature-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y=datatrain[0]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we construct our net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FinalResult(input,seuil):\n",
    "    return (input>seuil).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numlabels=labelscsv.shape[1]-1\n",
    "nbtrain=len(datatrain)\n",
    "nbvalidation=len(datavalidation)\n",
    "nbtest=len(datatest)\n",
    "basicexpansion=1  #resnet18, 34\n",
    "bottleneckexpansion=4   #resnet50,101,152\n",
    "weightpath = \"/local/zhu/Stage Yue code/exp3/exp3-weight18.pth\"#testweight.pth\"\n",
    "batchsize = 100\n",
    "useGPU = True\n",
    "seuil=torch.Tensor(numlabels)\n",
    "for i in range(numlabels):\n",
    "    seuil[i]=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a pretrained Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net=Weldon.resnet18_weldon(4, pretrained=True)\n",
    "#net=models.resnet18(pretrained=True)#, num_classes=4)#18,34,50,101,152\n",
    "#net.fc = nn.Linear(512 * basicexpansion, numlabels)#bottleneckexpansion\n",
    "if useGPU:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainloader = DataLoader(datatrain, batch_size=batchsize, sampler=Sampler.RandomSampler(datatrain))\n",
    "validationloader = DataLoader(datavalidation, batch_size=batchsize)\n",
    "testloader = DataLoader(datatest, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a pretrained model if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.exists(weightpath):\n",
    "    net.load_state_dict(torch.load(weightpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traingraph=[]\n",
    "testgraph=[]\n",
    "ConMatTrain=[]\n",
    "ConMatValidation=[]\n",
    "ConMatTest=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The first threshold is defined at \", seuil)\n",
    "newseuil=torch.Tensor(numlabels)\n",
    "\n",
    "ConfusionMatrixTrain=[torch.Tensor() for i in range(numlabels)]\n",
    "ConfusionMatrixValidation=[torch.Tensor() for i in range(numlabels)]\n",
    "ConfusionMatrixTest=[torch.Tensor() for i in range(numlabels)]\n",
    "APM=Meter.APMeter()\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "       \n",
    "    #--------------------------------------training period---------------------------------------\n",
    "    running_loss = 0.0\n",
    "    epochloss = 0.0\n",
    "    numsample=0\n",
    "    printfrequence=10000\n",
    "    for i in range(numlabels):\n",
    "        ConfusionMatrixTrain[i]=torch.IntTensor(2,2).zero_()\n",
    "    \n",
    "    net.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        if useGPU:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "   \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #trainging confusion matrix\n",
    "        result=FinalResult(outputs.data.cpu(), seuil.repeat(outputs.data.cpu().size(0),1))\n",
    "        for j in range(labels.data.cpu().size(0)):\n",
    "            for i in range(numlabels):\n",
    "                ConfusionMatrixTrain[i][int(labels.data.cpu()[j][i])][int(result.cpu()[j][i])]+=1\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        epochloss+=loss.data[0]\n",
    "        numsample += batchsize\n",
    "        if numsample % printfrequence == 0: #printfrequence-1:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.5f' % (epoch+1, numsample, running_loss / printfrequence))\n",
    "            running_loss = 0.0\n",
    "    print('The average loss of epoch ', epoch+1, ' is ', epochloss/nbtrain)\n",
    "    print('The confusion matrixs for training are: ', ConfusionMatrixTrain)\n",
    "    traingraph.append(epochloss/nbtrain)\n",
    "    ConMatTrain.append(ConfusionMatrixTrain.copy())\n",
    "    torch.save(net.state_dict(),weightpath)\n",
    "    \n",
    "    #--------------------------------------Validation period---------------------------------------\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    epochloss = 0.0\n",
    "    numsample=0\n",
    "    printfrequence=10000\n",
    "    for i in range(numlabels):\n",
    "        newseuil[i]=0.0\n",
    "        ConfusionMatrixValidation[i]=torch.IntTensor(2,2).zero_()\n",
    "    \n",
    "    net.eval()\n",
    "    for inputs, labels in validationloader:\n",
    "        if useGPU:\n",
    "            inputs = inputs.cuda()\n",
    "        outputs=net(Variable(inputs))\n",
    "        result=FinalResult(outputs.data.cpu(), seuil.repeat(outputs.data.cpu().size(0),1))\n",
    "        \n",
    "        #validation confusion matrix\n",
    "        for j in range(labels.cpu().size(0)):\n",
    "            newseuil+=outputs.data.cpu()[j]\n",
    "            numsample+=1\n",
    "            for i in range(numlabels):\n",
    "                ConfusionMatrixValidation[i][int(labels.cpu()[j][i])][int(result.cpu()[j][i])]+=1\n",
    "\n",
    "  \n",
    "    newseuil=newseuil/numsample\n",
    "    seuil=newseuil.clone()\n",
    "    print('The seuil of epoch', epoch+1, ' is defined at', seuil)\n",
    "    ConMatValidation.append(ConfusionMatrixValidation.copy())\n",
    "    #print('The confusion matrixs for validation are: ', ConfusionMatrixvalidation)\n",
    "    \n",
    "    #--------------------------------------Test period---------------------------------------\n",
    "    \n",
    "    APM.reset()\n",
    "    numsample=0\n",
    "    printfrequence=10000\n",
    "    classerror=torch.zeros(numlabels)\n",
    "    for i in range(numlabels):\n",
    "        ConfusionMatrixTest[i]=torch.IntTensor(2,2).zero_()\n",
    "        \n",
    "    net.eval()\n",
    "    for inputs, labels in testloader:\n",
    "        if useGPU:\n",
    "            inputs = inputs.cuda()\n",
    "            \n",
    "        outputs=net(Variable(inputs))\n",
    "        result=FinalResult(outputs.data.cpu(), seuil.repeat(outputs.data.cpu().size(0),1))\n",
    "        \n",
    "        for j in range(labels.size(0)):\n",
    "            classerror.add_(torch.Tensor.float((labels[j]-result.cpu()[j]).abs()))\n",
    "            numsample +=1\n",
    "            APM.add(outputs.data.cpu()[j], labels[j])\n",
    "            for i in range(numlabels):\n",
    "                ConfusionMatrixTest[i][int(labels[j][i])][int(result.cpu()[j][i])]+=1\n",
    "        \n",
    "        if numsample % printfrequence == 0: #printfrequence-1:    # print every 100 mini-batches\n",
    "            print(numsample, 'images passed')\n",
    "\n",
    "    \n",
    "    print('In total we have ', numsample, 'images for the test.')\n",
    "    print(\"The Average Precision are \", APM.value())\n",
    "    #print(\"The correctness per class are \", torch.ones(numlabels).sub(classerror.div_(numsample)))\n",
    "    print(\"The mean test loss is \", classerror.div_(numsample).mean())\n",
    "    print('The confusion matrixs for test are: ', ConfusionMatrixTest)\n",
    "    ConMatTest.append(ConfusionMatrixTest.copy())\n",
    "    testgraph.append(classerror.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot([1,2,3,4])\n",
    "plt.axis([0, 10, 0, 0.5])\n",
    "\n",
    "plt.plot(traingraph, label=\"training loss\")\n",
    "plt.plot(testgraph, label=\"test loss\")\n",
    "legend = plt.legend()\n",
    "\n",
    "plt.ylabel('mean loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot([1,2,3,4])\n",
    "plt.axis([0, 10, 0.75, 1])\n",
    "\n",
    "x1=[0.75, 0.9859, 0.9938, 0.9926, 0.9940, 0.9943, 0.9946, 0.9953, 0.9987]\n",
    "x2=[0.75, 0.8497, 0.8810, 0.9054, 0.8920, 0.9360, 0.9500, 0.9181, 0.9349]\n",
    "x3=[0.75, 0.9711, 0.9800, 0.9848, 0.9856, 0.9930, 0.9890, 0.9922, 0.9943]\n",
    "x4=[0.75, 0.9674, 0.9591, 0.9761, 0.9897, 0.9834, 0.9881, 0.9974, 0.9894]\n",
    "\n",
    "y1=[0.9791, 0.9748, 0.9785, 0.9635, 0.9793, 0.9803, 0.9625, 0.9768, 0.9773]\n",
    "y2=[0.7766, 0.8092, 0.8271, 0.8145, 0.8455, 0.8559, 0.8602, 0.8586, 0.8637]\n",
    "y3=[0.9328, 0.9251, 0.9265, 0.9537, 0.9620, 0.9511, 0.9432, 0.9288, 0.9583]\n",
    "y4=[0.9470, 0.9358, 0.9466, 0.9527, 0.9540, 0.9533, 0.9613, 0.9481, 0.9616]\n",
    "\n",
    "plt.plot(x1, label=\"train lisse-dente\")\n",
    "plt.plot(x2, label=\"train alterne-oppose\")\n",
    "plt.plot(x3, label=\"train simple-composee\")\n",
    "plt.plot(x4, label=\"train non ligneux-ligneux\")\n",
    "\n",
    "plt.plot(y1, label=\"test lisse-dente\")\n",
    "plt.plot(y2, label=\"test alterne-oppose\")\n",
    "plt.plot(y3, label=\"test simple-composee\")\n",
    "plt.plot(y4, label=\"test non ligneux-ligneux\")\n",
    "\n",
    "legend = plt.legend()\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Correctness par class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
