{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection in the street"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is the main notebook (temporary just a structure now of all steps that we can do) for our DL4CV project. Our aim is to detect the object in the street by means of a convolutional neural network. The detection will be like a segmentation task with find out what each pixel of the object in a photo belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, sampler\n",
    "from MyFolder import MyImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This step should be to load the data images and the label images (by pixel), while doing feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--In leftImg8bit.zip, the train and test images are all 8-bit 2048*1024 pixels png type images. \n",
    "\n",
    "--In gtCoarse, the train and test labels are all 2048*1024 pixels png type images, which ONLY color the road in pink and the small objects on it in blue, the other pixels are black.\n",
    "\n",
    "-- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelscsv = pd.read_csv(\"../Downloads/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labelscsv.shape)\n",
    "print(labelscsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def labeltransform(img):\n",
    "#    input=transforms.ToTensor()(img)\n",
    "#    target=torch.IntTensor(1024, 2048).zero_()\n",
    "#    for i in range(1024):\n",
    "#        for j in range(2048):\n",
    "#            target[i][j]=255\n",
    "#            for k in range(labelscsv.shape[0]):\n",
    "#                if (labelscsv.iloc[k][2]<200 and labelscsv.iloc[k][7]/255==input[0][i][j] and labelscsv.iloc[k][8]/255==input[1][i][j] and labelscsv.iloc[k][9]/255==input[2][i][j]):\n",
    "#                    target[i][j]=labelscsv.iloc[k][2]\n",
    "#    return(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pre-training of the images contains the following steps:\n",
    "\n",
    "--Using transform.Scale to rize the images into width = 256 (To be modified)\n",
    "\n",
    "--take the center part with 224 x 224 (We know that the resnet requires an input of 224 x 224)\n",
    "\n",
    "--transforms each pixel from [0,255] to [0,1] \n",
    "--> Are we sure we want to do this? Won't we lose resolution? \n",
    "\n",
    "--Normalisation for resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "#    [transforms.Scale(256),\n",
    "#     [transforms.CenterCrop(224),     \n",
    "     [transforms.ToTensor()])\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "targettransform = transforms.Compose(\n",
    "#    [transforms.Scale(256),\n",
    "#     [transforms.CenterCrop(224),  \n",
    "     [transforms.ToTensor(),\n",
    "     transforms.Normalize((0, 0, 0), (1/255, 1/255, 1/255))])\n",
    "datatrain = MyImageFolder(root1='../Downloads/leftImg8bit/train', root2='../Downloads/gtFine/train' , transform = transform , target_transform= targettransform)\n",
    "dataval = MyImageFolder(root1='../Downloads/leftImg8bit/val', root2='../Downloads/gtFine/val' , transform = transform , target_transform= targettransform)\n",
    "datatest = MyImageFolder(root1='../Downloads/leftImg8bit/test', root2='../Downloads/gtFine/test' , transform = transform , target_transform= targettransform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of the data after feature-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=datatrain[0]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we construct our net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Mynet import PretrainedResNet50, MyNet\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = labelscsv.shape[0]-1\n",
    "nbtrain=len(datatrain)\n",
    "nbval=len(dataval)\n",
    "nbtest=len(datatest)\n",
    "weightpath = \"../Downloads/dlcv_weight50.pth\"#testweight.pth\"\n",
    "batchsize = 1\n",
    "useGPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a pretrained Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_net = PretrainedResNet50()\n",
    "pretrained_net.load_state_dict(models.resnet50(pretrained=True).state_dict())\n",
    "net = MyNet(num_classes, pretrained_net)\n",
    "if useGPU:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "if useGPU:\n",
    "    criterion.cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainloader = DataLoader(datatrain, batch_size=batchsize, sampler=sampler.RandomSampler(datatrain))\n",
    "valloader = DataLoader(dataval, batch_size=batchsize)\n",
    "testloader = DataLoader(datatest, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a pretrained model if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.exists(weightpath):\n",
    "    net.load_state_dict(torch.load(weightpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start training\")\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "       \n",
    "    #--------------------------------------training period---------------------------------------\n",
    "    running_loss = 0.0\n",
    "    epochloss = 0.0\n",
    "    numsample=0\n",
    "    printfrequence=10\n",
    "    \n",
    "    net.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        if useGPU:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "   \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        epochloss+=loss.data[0]\n",
    "        numsample += batchsize\n",
    "        if numsample % printfrequence == 0: #printfrequence-1: \n",
    "            print('[%d, %5d] loss: %.5f' % (epoch+1, numsample, running_loss / printfrequence))\n",
    "            running_loss = 0.0\n",
    "    print('The average loss of epoch ', epoch+1, ' is ', epochloss/nbtrain)\n",
    "    torch.save(net.state_dict(),weightpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Start training\")\n",
    "newseuil=torch.Tensor(numlabels)\n",
    "\n",
    "ConfusionMatrixTrain=[torch.Tensor() for i in range(numlabels)]\n",
    "ConfusionMatrixValidation=[torch.Tensor() for i in range(numlabels)]\n",
    "ConfusionMatrixTest=[torch.Tensor() for i in range(numlabels)]\n",
    "APM=Meter.APMeter()\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "       \n",
    "    #--------------------------------------training period---------------------------------------\n",
    "    running_loss = 0.0\n",
    "    epochloss = 0.0\n",
    "    numsample=0\n",
    "    printfrequence=10000\n",
    "    for i in range(numlabels):\n",
    "        ConfusionMatrixTrain[i]=torch.IntTensor(2,2).zero_()\n",
    "    \n",
    "    net.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        if useGPU:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "   \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #trainging confusion matrix\n",
    "        result=FinalResult(outputs.data.cpu(), seuil.repeat(outputs.data.cpu().size(0),1))\n",
    "        for j in range(labels.data.cpu().size(0)):\n",
    "            for i in range(numlabels):\n",
    "                ConfusionMatrixTrain[i][int(labels.data.cpu()[j][i])][int(result.cpu()[j][i])]+=1\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        epochloss+=loss.data[0]\n",
    "        numsample += batchsize\n",
    "        if numsample % printfrequence == 0: #printfrequence-1:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.5f' % (epoch+1, numsample, running_loss / printfrequence))\n",
    "            running_loss = 0.0\n",
    "    print('The average loss of epoch ', epoch+1, ' is ', epochloss/nbtrain)\n",
    "    print('The confusion matrixs for training are: ', ConfusionMatrixTrain)\n",
    "    traingraph.append(epochloss/nbtrain)\n",
    "    ConMatTrain.append(ConfusionMatrixTrain.copy())\n",
    "    torch.save(net.state_dict(),weightpath)\n",
    "    \n",
    "    #--------------------------------------Validation period---------------------------------------\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    epochloss = 0.0\n",
    "    numsample=0\n",
    "    printfrequence=10000\n",
    "    for i in range(numlabels):\n",
    "        newseuil[i]=0.0\n",
    "        ConfusionMatrixValidation[i]=torch.IntTensor(2,2).zero_()\n",
    "    \n",
    "    net.eval()\n",
    "    for inputs, labels in validationloader:\n",
    "        if useGPU:\n",
    "            inputs = inputs.cuda()\n",
    "        outputs=net(Variable(inputs))\n",
    "        result=FinalResult(outputs.data.cpu(), seuil.repeat(outputs.data.cpu().size(0),1))\n",
    "        \n",
    "        #validation confusion matrix\n",
    "        for j in range(labels.cpu().size(0)):\n",
    "            newseuil+=outputs.data.cpu()[j]\n",
    "            numsample+=1\n",
    "            for i in range(numlabels):\n",
    "                ConfusionMatrixValidation[i][int(labels.cpu()[j][i])][int(result.cpu()[j][i])]+=1\n",
    "\n",
    "  \n",
    "    newseuil=newseuil/numsample\n",
    "    seuil=newseuil.clone()\n",
    "    print('The seuil of epoch', epoch+1, ' is defined at', seuil)\n",
    "    ConMatValidation.append(ConfusionMatrixValidation.copy())\n",
    "    #print('The confusion matrixs for validation are: ', ConfusionMatrixvalidation)\n",
    "    \n",
    "    #--------------------------------------Test period---------------------------------------\n",
    "    \n",
    "    APM.reset()\n",
    "    numsample=0\n",
    "    printfrequence=10000\n",
    "    classerror=torch.zeros(numlabels)\n",
    "    for i in range(numlabels):\n",
    "        ConfusionMatrixTest[i]=torch.IntTensor(2,2).zero_()\n",
    "        \n",
    "    net.eval()\n",
    "    for inputs, labels in testloader:\n",
    "        if useGPU:\n",
    "            inputs = inputs.cuda()\n",
    "            \n",
    "        outputs=net(Variable(inputs))\n",
    "        result=FinalResult(outputs.data.cpu(), seuil.repeat(outputs.data.cpu().size(0),1))\n",
    "        \n",
    "        for j in range(labels.size(0)):\n",
    "            classerror.add_(torch.Tensor.float((labels[j]-result.cpu()[j]).abs()))\n",
    "            numsample +=1\n",
    "            APM.add(outputs.data.cpu()[j], labels[j])\n",
    "            for i in range(numlabels):\n",
    "                ConfusionMatrixTest[i][int(labels[j][i])][int(result.cpu()[j][i])]+=1\n",
    "        \n",
    "        if numsample % printfrequence == 0: #printfrequence-1:    # print every 100 mini-batches\n",
    "            print(numsample, 'images passed')\n",
    "\n",
    "    \n",
    "    print('In total we have ', numsample, 'images for the test.')\n",
    "    print(\"The Average Precision are \", APM.value())\n",
    "    #print(\"The correctness per class are \", torch.ones(numlabels).sub(classerror.div_(numsample)))\n",
    "    print(\"The mean test loss is \", classerror.div_(numsample).mean())\n",
    "    print('The confusion matrixs for test are: ', ConfusionMatrixTest)\n",
    "    ConMatTest.append(ConfusionMatrixTest.copy())\n",
    "    testgraph.append(classerror.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot([1,2,3,4])\n",
    "plt.axis([0, 10, 0, 0.5])\n",
    "\n",
    "plt.plot(traingraph, label=\"training loss\")\n",
    "plt.plot(testgraph, label=\"test loss\")\n",
    "legend = plt.legend()\n",
    "\n",
    "plt.ylabel('mean loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot([1,2,3,4])\n",
    "plt.axis([0, 10, 0.75, 1])\n",
    "\n",
    "x1=[0.75, 0.9859, 0.9938, 0.9926, 0.9940, 0.9943, 0.9946, 0.9953, 0.9987]\n",
    "x2=[0.75, 0.8497, 0.8810, 0.9054, 0.8920, 0.9360, 0.9500, 0.9181, 0.9349]\n",
    "x3=[0.75, 0.9711, 0.9800, 0.9848, 0.9856, 0.9930, 0.9890, 0.9922, 0.9943]\n",
    "x4=[0.75, 0.9674, 0.9591, 0.9761, 0.9897, 0.9834, 0.9881, 0.9974, 0.9894]\n",
    "\n",
    "y1=[0.9791, 0.9748, 0.9785, 0.9635, 0.9793, 0.9803, 0.9625, 0.9768, 0.9773]\n",
    "y2=[0.7766, 0.8092, 0.8271, 0.8145, 0.8455, 0.8559, 0.8602, 0.8586, 0.8637]\n",
    "y3=[0.9328, 0.9251, 0.9265, 0.9537, 0.9620, 0.9511, 0.9432, 0.9288, 0.9583]\n",
    "y4=[0.9470, 0.9358, 0.9466, 0.9527, 0.9540, 0.9533, 0.9613, 0.9481, 0.9616]\n",
    "\n",
    "plt.plot(x1, label=\"train lisse-dente\")\n",
    "plt.plot(x2, label=\"train alterne-oppose\")\n",
    "plt.plot(x3, label=\"train simple-composee\")\n",
    "plt.plot(x4, label=\"train non ligneux-ligneux\")\n",
    "\n",
    "plt.plot(y1, label=\"test lisse-dente\")\n",
    "plt.plot(y2, label=\"test alterne-oppose\")\n",
    "plt.plot(y3, label=\"test simple-composee\")\n",
    "plt.plot(y4, label=\"test non ligneux-ligneux\")\n",
    "\n",
    "legend = plt.legend()\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Correctness par class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
